2023-11-22 20:29:54,401 P610278 INFO Params: {
    "V_net_dropout": "0.1",
    "W_net_dropout": "0.1",
    "alpha": "0.1",
    "batch_norm": "True",
    "batch_size": "10000",
    "beta": "0.1",
    "cl_temperature": "0.3",
    "data_format": "h5",
    "data_root": "../../../data/",
    "dataset_id": "Frappe_x1_h5",
    "debug_mode": "False",
    "delta": "0.7",
    "early_stop_patience": "2",
    "embedding_dim": "20",
    "embedding_regularizer": "0.05",
    "epochs": "100",
    "eps": "1e-05",
    "eval_steps": "None",
    "feature_cols": "[{'active': True, 'dtype': 'float', 'name': ['user', 'item', 'daytime', 'weekday', 'isweekend', 'homework', 'cost', 'weather', 'country', 'city'], 'type': 'categorical'}]",
    "feature_config": "None",
    "feature_specs": "None",
    "fi_hidden_units": "[400, 400]",
    "gpu": "1",
    "group_id": "None",
    "hidden_activations": "['relu', 'mish', 'gelu']",
    "label_col": "{'dtype': 'float', 'name': 'label'}",
    "learning_rate": "0.001",
    "loss": "binary_crossentropy",
    "metrics": "['logloss', 'AUC']",
    "min_categr_count": "2",
    "model": "CETN",
    "model_id": "CETN_Frappe_007_7951f5fa",
    "model_root": "./checkpoints/",
    "monitor": "{'AUC': 1, 'logloss': -1}",
    "monitor_mode": "max",
    "net_regularizer": "0",
    "num_workers": "32",
    "optimizer": "adam",
    "perturbed": "False",
    "pickle_feature_encoder": "True",
    "save_best_only": "True",
    "seed": "2023",
    "shuffle": "True",
    "task": "binary_classification",
    "test_data": "../../../data/Frappe_x1_h5/test.h5",
    "through": "True",
    "train_data": "../../../data/Frappe_x1_h5/train.h5",
    "use_features": "None",
    "valid_data": "../../../data/Frappe_x1_h5/valid.h5",
    "verbose": "1",
    "w_hidden_units": "[400]"
}
2023-11-22 20:29:54,402 P610278 INFO Load feature_map from json: ../../../data/Frappe_x1_h5/feature_map.json
2023-11-22 20:29:54,402 P610278 INFO Set column index...
2023-11-22 20:29:54,403 P610278 INFO Feature specs: {
    "city": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 232, 'vocab_size': 233}",
    "cost": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 3, 'vocab_size': 4}",
    "country": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 81, 'vocab_size': 82}",
    "daytime": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 8, 'vocab_size': 9}",
    "homework": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 4, 'vocab_size': 5}",
    "isweekend": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 3, 'vocab_size': 4}",
    "item": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 4083, 'vocab_size': 4084}",
    "user": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 941, 'vocab_size': 942}",
    "weather": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 10, 'vocab_size': 11}",
    "weekday": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 8, 'vocab_size': 9}"
}
2023-11-22 20:30:00,854 P610278 INFO Total number of parameters: 1684866.
2023-11-22 20:30:00,854 P610278 INFO Loading data...
2023-11-22 20:30:00,854 P610278 INFO Loading data from h5: ../../../data/Frappe_x1_h5/train.h5
2023-11-22 20:30:00,879 P610278 INFO Train samples: total/202027, blocks/1
2023-11-22 20:30:00,879 P610278 INFO Loading data from h5: ../../../data/Frappe_x1_h5/valid.h5
2023-11-22 20:30:00,886 P610278 INFO Validation samples: total/57722, blocks/1
2023-11-22 20:30:00,886 P610278 INFO Loading train and validation data done.
2023-11-22 20:30:00,886 P610278 INFO Start training: 21 batches/epoch
2023-11-22 20:30:00,886 P610278 INFO ************ Epoch=1 start ************
2023-11-22 20:30:04,618 P610278 INFO Train loss: 1.097492
2023-11-22 20:30:04,619 P610278 INFO Evaluation @epoch 1 - batch 21: 
2023-11-22 20:30:08,370 P610278 INFO ===
2023-11-22 20:30:08,370 P610278 INFO [Metrics] AUC: 0.735613 - logloss: 0.680372
2023-11-22 20:30:08,370 P610278 INFO Save best model: monitor(max)=0.055240
2023-11-22 20:30:08,644 P610278 INFO ************ Epoch=1 end ************
2023-11-22 20:30:13,016 P610278 INFO Train loss: 0.921936
2023-11-22 20:30:13,021 P610278 INFO Evaluation @epoch 2 - batch 21: 
2023-11-22 20:30:16,562 P610278 INFO ===
2023-11-22 20:30:16,562 P610278 INFO [Metrics] AUC: 0.839308 - logloss: 0.656470
2023-11-22 20:30:16,563 P610278 INFO Save best model: monitor(max)=0.182838
2023-11-22 20:30:16,763 P610278 INFO ************ Epoch=2 end ************
2023-11-22 20:30:20,356 P610278 INFO Train loss: 0.839098
2023-11-22 20:30:20,356 P610278 INFO Evaluation @epoch 3 - batch 21: 
2023-11-22 20:30:24,428 P610278 INFO ===
2023-11-22 20:30:24,428 P610278 INFO [Metrics] AUC: 0.942844 - logloss: 0.613285
2023-11-22 20:30:24,428 P610278 INFO Save best model: monitor(max)=0.329559
2023-11-22 20:30:24,662 P610278 INFO ************ Epoch=3 end ************
2023-11-22 20:30:28,302 P610278 INFO Train loss: 0.793265
2023-11-22 20:30:28,303 P610278 INFO Evaluation @epoch 4 - batch 21: 
2023-11-22 20:30:31,454 P610278 INFO ===
2023-11-22 20:30:31,454 P610278 INFO [Metrics] AUC: 0.969725 - logloss: 0.390454
2023-11-22 20:30:31,454 P610278 INFO Save best model: monitor(max)=0.579271
2023-11-22 20:30:31,706 P610278 INFO ************ Epoch=4 end ************
2023-11-22 20:30:35,237 P610278 INFO Train loss: 0.771292
2023-11-22 20:30:35,238 P610278 INFO Evaluation @epoch 5 - batch 21: 
2023-11-22 20:30:38,937 P610278 INFO ===
2023-11-22 20:30:38,941 P610278 INFO [Metrics] AUC: 0.979262 - logloss: 0.164285
2023-11-22 20:30:38,941 P610278 INFO Save best model: monitor(max)=0.814977
2023-11-22 20:30:39,218 P610278 INFO ************ Epoch=5 end ************
2023-11-22 20:30:42,549 P610278 INFO Train loss: 0.753988
2023-11-22 20:30:42,549 P610278 INFO Evaluation @epoch 6 - batch 21: 
2023-11-22 20:30:46,043 P610278 INFO ===
2023-11-22 20:30:46,043 P610278 INFO [Metrics] AUC: 0.981951 - logloss: 0.204683
2023-11-22 20:30:46,044 P610278 INFO Monitor(max)=0.777269 STOP!
2023-11-22 20:30:46,044 P610278 INFO Reduce learning rate on plateau: 0.000100
2023-11-22 20:30:46,318 P610278 INFO ************ Epoch=6 end ************
2023-11-22 20:30:50,465 P610278 INFO Train loss: 0.721486
2023-11-22 20:30:50,465 P610278 INFO Evaluation @epoch 7 - batch 21: 
2023-11-22 20:30:54,013 P610278 INFO ===
2023-11-22 20:30:54,014 P610278 INFO [Metrics] AUC: 0.984030 - logloss: 0.167248
2023-11-22 20:30:54,014 P610278 INFO Save best model: monitor(max)=0.816781
2023-11-22 20:30:54,265 P610278 INFO ************ Epoch=7 end ************
2023-11-22 20:30:58,342 P610278 INFO Train loss: 0.702982
2023-11-22 20:30:58,342 P610278 INFO Evaluation @epoch 8 - batch 21: 
2023-11-22 20:31:01,656 P610278 INFO ===
2023-11-22 20:31:01,656 P610278 INFO [Metrics] AUC: 0.984927 - logloss: 0.166054
2023-11-22 20:31:01,656 P610278 INFO Save best model: monitor(max)=0.818874
2023-11-22 20:31:01,898 P610278 INFO ************ Epoch=8 end ************
2023-11-22 20:31:05,980 P610278 INFO Train loss: 0.691046
2023-11-22 20:31:05,981 P610278 INFO Evaluation @epoch 9 - batch 21: 
2023-11-22 20:31:09,079 P610278 INFO ===
2023-11-22 20:31:09,089 P610278 INFO [Metrics] AUC: 0.985202 - logloss: 0.167251
2023-11-22 20:31:09,089 P610278 INFO Monitor(max)=0.817951 STOP!
2023-11-22 20:31:09,089 P610278 INFO Reduce learning rate on plateau: 0.000010
2023-11-22 20:31:09,256 P610278 INFO ************ Epoch=9 end ************
2023-11-22 20:31:12,641 P610278 INFO Train loss: 0.684604
2023-11-22 20:31:12,641 P610278 INFO Evaluation @epoch 10 - batch 21: 
2023-11-22 20:31:16,192 P610278 INFO ===
2023-11-22 20:31:16,192 P610278 INFO [Metrics] AUC: 0.985316 - logloss: 0.154430
2023-11-22 20:31:16,193 P610278 INFO Save best model: monitor(max)=0.830886
2023-11-22 20:31:16,458 P610278 INFO ************ Epoch=10 end ************
2023-11-22 20:31:20,056 P610278 INFO Train loss: 0.683725
2023-11-22 20:31:20,056 P610278 INFO Evaluation @epoch 11 - batch 21: 
2023-11-22 20:31:23,614 P610278 INFO ===
2023-11-22 20:31:23,614 P610278 INFO [Metrics] AUC: 0.985378 - logloss: 0.153191
2023-11-22 20:31:23,614 P610278 INFO Save best model: monitor(max)=0.832187
2023-11-22 20:31:23,829 P610278 INFO ************ Epoch=11 end ************
2023-11-22 20:31:28,310 P610278 INFO Train loss: 0.682890
2023-11-22 20:31:28,311 P610278 INFO Evaluation @epoch 12 - batch 21: 
2023-11-22 20:31:31,616 P610278 INFO ===
2023-11-22 20:31:31,617 P610278 INFO [Metrics] AUC: 0.985393 - logloss: 0.153213
2023-11-22 20:31:31,617 P610278 INFO Monitor(max)=0.832181 STOP!
2023-11-22 20:31:31,617 P610278 INFO Reduce learning rate on plateau: 0.000001
2023-11-22 20:31:31,783 P610278 INFO ************ Epoch=12 end ************
2023-11-22 20:31:35,891 P610278 INFO Train loss: 0.682024
2023-11-22 20:31:35,897 P610278 INFO Evaluation @epoch 13 - batch 21: 
2023-11-22 20:31:39,751 P610278 INFO ===
2023-11-22 20:31:39,751 P610278 INFO [Metrics] AUC: 0.985398 - logloss: 0.152300
2023-11-22 20:31:39,751 P610278 INFO Save best model: monitor(max)=0.833097
2023-11-22 20:31:40,033 P610278 INFO ************ Epoch=13 end ************
2023-11-22 20:31:43,865 P610278 INFO Train loss: 0.682651
2023-11-22 20:31:43,865 P610278 INFO Evaluation @epoch 14 - batch 21: 
2023-11-22 20:31:47,276 P610278 INFO ===
2023-11-22 20:31:47,276 P610278 INFO [Metrics] AUC: 0.985398 - logloss: 0.152066
2023-11-22 20:31:47,277 P610278 INFO Save best model: monitor(max)=0.833332
2023-11-22 20:31:47,578 P610278 INFO ************ Epoch=14 end ************
2023-11-22 20:31:52,312 P610278 INFO Train loss: 0.682743
2023-11-22 20:31:52,312 P610278 INFO Evaluation @epoch 15 - batch 21: 
2023-11-22 20:31:55,603 P610278 INFO ===
2023-11-22 20:31:55,603 P610278 INFO [Metrics] AUC: 0.985402 - logloss: 0.152141
2023-11-22 20:31:55,604 P610278 INFO Monitor(max)=0.833261 STOP!
2023-11-22 20:31:55,604 P610278 INFO Reduce learning rate on plateau: 0.000001
2023-11-22 20:31:55,821 P610278 INFO ************ Epoch=15 end ************
2023-11-22 20:32:00,127 P610278 INFO Train loss: 0.681758
2023-11-22 20:32:00,127 P610278 INFO Evaluation @epoch 16 - batch 21: 
2023-11-22 20:32:03,790 P610278 INFO ===
2023-11-22 20:32:03,790 P610278 INFO [Metrics] AUC: 0.985404 - logloss: 0.152073
2023-11-22 20:32:03,790 P610278 INFO Monitor(max)=0.833331 STOP!
2023-11-22 20:32:03,791 P610278 INFO Reduce learning rate on plateau: 0.000001
2023-11-22 20:32:03,791 P610278 INFO ********* Epoch==16 early stop *********
2023-11-22 20:32:04,005 P610278 INFO Training finished.
2023-11-22 20:32:04,005 P610278 INFO Load best model: /mnt/public/lhh/code/model_zoo/CETN/CETN_torch/checkpoints/Frappe_x1_h5/CETN_Frappe_007_7951f5fa.model
2023-11-22 20:32:04,036 P610278 INFO ****** Validation evaluation ******
2023-11-22 20:32:07,430 P610278 INFO ===
2023-11-22 20:32:07,430 P610278 INFO [Metrics] logloss: 0.152066 - AUC: 0.985398
2023-11-22 20:32:07,490 P610278 INFO ******** Test evaluation ********
2023-11-22 20:32:07,490 P610278 INFO Loading data...
2023-11-22 20:32:07,490 P610278 INFO Loading data from h5: ../../../data/Frappe_x1_h5/test.h5
2023-11-22 20:32:07,497 P610278 INFO Test samples: total/28860, blocks/1
2023-11-22 20:32:07,497 P610278 INFO Loading test data done.
2023-11-22 20:32:11,492 P610278 INFO ===
2023-11-22 20:32:11,492 P610278 INFO [Metrics] logloss: 0.149942 - AUC: 0.985730
